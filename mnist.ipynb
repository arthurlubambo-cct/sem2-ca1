{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd44d7a3-349b-4793-b42a-ae3d0b32e50c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 16:12:08.969314: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-05 16:12:09.793455: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-05 16:12:09.793499: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-05 16:12:09.798422: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-05 16:12:10.280159: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-05 16:12:10.283727: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-05 16:12:12.686781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a5e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from pyspark.sql.types import StructType,StructField, StringType, FloatType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9bea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3df554-27da-41e1-9756-0cedc4998fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train, test load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize values to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c42cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PY SPARK VERSION OF THE DATAFRAME\n",
    "# def get_ps_dataFrame(x_data,y_data):\n",
    "#     data_unified = [( x_data[i].tolist(), str(y_data[i])) for i in range(len(x_data))]\n",
    "#     schema = StructType([ \n",
    "#         StructField(\"image\",ArrayType(ArrayType(FloatType())),False), \n",
    "#         StructField(\"class\", StringType(), False) \n",
    "#       ])\n",
    "#     df = spark.createDataFrame(data=data_unified,schema=schema)\n",
    "#     return df\n",
    "# train_df = get_ps_dataFrame(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc0ede4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa5888ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_dataFrame(x_data,y_data):\n",
    "    return pd.DataFrame(data={'image':x_data.tolist(), 'class':y_data.tolist()})\n",
    "train_df = get_pd_dataFrame(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38eeb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_cross_same_class_pair(df:pd.DataFrame):\n",
    "    sorted_df = df.sort_values(\"class\").reset_index(drop=True)\n",
    "    shuffled_sorted_df = sorted_df.sample(frac=1).reset_index(drop=True).sort_values(\"class\").reset_index(drop=True)\n",
    "    shuffled_sorted_df.rename(columns={'image':'imagePair',\"class\": \"classPair\"}, inplace=True)\n",
    "    result = pd.concat([sorted_df, shuffled_sorted_df], axis=1)\n",
    "    return result[['image','imagePair', 'class']].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "same_class_cross_df = augment_data_cross_same_class_pair(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1875063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def series_to_tensor(series):\n",
    "    tensor_list = series.apply(lambda x: tf.constant(x))\n",
    "    return tf.stack(tensor_list)\n",
    "    \n",
    "def prepare_train_traditional_autoencoder_data(train_df):\n",
    "    image_tensor = series_to_tensor(train_df['image'])\n",
    "    in_x_train = image_tensor\n",
    "    out_x_train = image_tensor\n",
    "    return [in_x_train, out_x_train]\n",
    "\n",
    "def prepare_train_cross_same_class_autoencoder_data(train_df, additional_same_class_df):\n",
    "    original_df =  train_df.copy()\n",
    "    original_df[\"imagePair\"] = original_df[\"image\"]\n",
    "    concat_df = pd.concat([original_df, additional_same_class_df])\n",
    "    concat_df = concat_df.sample(frac=1).reset_index(drop=True)\n",
    "    in_x_train = series_to_tensor(concat_df['image'])\n",
    "    out_x_train = series_to_tensor(concat_df['imagePair'])\n",
    "    return [in_x_train, out_x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9f2999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[trad_ae_x_in,  trad_ae_x_out]= prepare_train_traditional_autoencoder_data(train_df)\n",
    "\n",
    "[cross_same_class_ae_x_in,  cross_same_class_ae_x_out]= prepare_train_cross_same_class_autoencoder_data(train_df, same_class_cross_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "653ed98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b5c3ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_166 (Conv2D)         (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_72 (MaxPooli  (None, 14, 14, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_167 (Conv2D)         (None, 14, 14, 8)         1160      \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPooli  (None, 7, 7, 8)           0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_168 (Conv2D)         (None, 7, 7, 8)           584       \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPooli  (None, 4, 4, 8)           0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_169 (Conv2D)         (None, 4, 4, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d_69 (UpSampli  (None, 8, 8, 8)           0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_170 (Conv2D)         (None, 8, 8, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d_70 (UpSampli  (None, 16, 16, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_171 (Conv2D)         (None, 14, 14, 16)        1168      \n",
      "                                                                 \n",
      " up_sampling2d_71 (UpSampli  (None, 28, 28, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_172 (Conv2D)         (None, 28, 28, 1)         145       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4385 (17.13 KB)\n",
      "Trainable params: 4385 (17.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fd7b7e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "235/235 [==============================] - 28s 111ms/step - loss: 0.2858 - val_loss: 0.1796\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.1582 - val_loss: 0.1427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f69f70ba8c0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(trad_ae_x_in, trad_ae_x_in,\n",
    "                epochs=2,#100\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9fce0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "class Autoencoder(keras.Model):\n",
    "    def __init__(self, latent_dim, input_shape ):\n",
    "        super(Autoencoder, self).__init__(input_shape,input_shape)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.shape = shape\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Conv2D(16, (3, 3), activation='relu', input_shape=shape),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "        ])\n",
    "        encoder_output_shape = self.encoder.layers[-1].output_shape\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same', input_shape=encoder_output_shape[1:]),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs,training = False):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "input_shape = keras.Input(shape=(28, 28, 1))\n",
    "latent_dim = 2\n",
    "ae = Autoencoder(latent_dim, input_shape)\n",
    "ae.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0aee4ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_45 (Sequential)  (None, 4, 4, 8)           1904      \n",
      "                                                                 \n",
      " sequential_46 (Sequential)  (None, 28, 28, 1)         2481      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4385 (17.13 KB)\n",
      "Trainable params: 4385 (17.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7db29194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1164 - val_loss: 0.1141\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1142 - val_loss: 0.1121\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 22s 91ms/step - loss: 0.1123 - val_loss: 0.1104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6a03521240>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ae.fit(trad_ae_x_in, trad_ae_x_in,\n",
    "                epochs=3,#100\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                workers=3,\n",
    "                use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19b05111-3762-494b-8629-6217d32f71cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train autoencoder\n",
    "# plot loss ae\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "62ae07bc-3346-4852-9eaf-923a077549f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare data aumentated for same class match\n",
    "# train VAE \n",
    "# plot loss vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c353b218-6261-46ec-84ca-beb69852f5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate encoded_vector_ae using autoencoder\n",
    "# calculate encoded_vector_vae using Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aea79c74-becf-4c31-bc64-02559ca94498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create function to calculate metric topK class metric\n",
    "# calculateMetric(encoded_vector_ae)\n",
    "# calculateMetric(encoded_vector_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24676f1e-eae5-4ac4-928e-2527739e3233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data visualisation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b28ecc1-7480-4b90-b15c-703302195d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# discuss results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a3847-9a99-4b6e-9939-8ee23bd781cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is time, apply in another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405144b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
