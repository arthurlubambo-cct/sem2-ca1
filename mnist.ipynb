{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd44d7a3-349b-4793-b42a-ae3d0b32e50c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a5e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from pyspark.sql.types import StructType,StructField, StringType, FloatType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9bea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3df554-27da-41e1-9756-0cedc4998fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train, test load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize values to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c42cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PY SPARK VERSION OF THE DATAFRAME\n",
    "# def get_ps_dataFrame(x_data,y_data):\n",
    "#     data_unified = [( x_data[i].tolist(), str(y_data[i])) for i in range(len(x_data))]\n",
    "#     schema = StructType([ \n",
    "#         StructField(\"image\",ArrayType(ArrayType(FloatType())),False), \n",
    "#         StructField(\"class\", StringType(), False) \n",
    "#       ])\n",
    "#     df = spark.createDataFrame(data=data_unified,schema=schema)\n",
    "#     return df\n",
    "# train_df = get_ps_dataFrame(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc0ede4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa5888ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_dataFrame(x_data,y_data):\n",
    "    return pd.DataFrame(data={'image':x_data.tolist(), 'class':y_data.tolist()})\n",
    "train_df = get_pd_dataFrame(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38eeb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_cross_same_class_pair(df:pd.DataFrame):\n",
    "    sorted_df = df.sort_values(\"class\").reset_index(drop=True)\n",
    "    shuffled_sorted_df = sorted_df.sample(frac=1).reset_index(drop=True).sort_values(\"class\").reset_index(drop=True)\n",
    "    shuffled_sorted_df.rename(columns={'image':'imagePair',\"class\": \"classPair\"}, inplace=True)\n",
    "    result = pd.concat([sorted_df, shuffled_sorted_df], axis=1)\n",
    "    return result[['image','imagePair', 'class']].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "same_class_cross_df = augment_data_cross_same_class_pair(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1875063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def series_to_tensor(series):\n",
    "    tensor_list = series.apply(lambda x: tf.constant(x))\n",
    "    return tf.stack(tensor_list)\n",
    "    \n",
    "def prepare_train_traditional_autoencoder_data(train_df):\n",
    "    image_tensor = series_to_tensor(train_df['image'])\n",
    "    in_x_train = image_tensor\n",
    "    out_x_train = image_tensor\n",
    "    return [in_x_train, out_x_train]\n",
    "\n",
    "def prepare_train_cross_same_class_autoencoder_data(train_df, additional_same_class_df):\n",
    "    original_df =  train_df.copy()\n",
    "    original_df[\"imagePair\"] = original_df[\"image\"]\n",
    "    concat_df = pd.concat([original_df, additional_same_class_df])\n",
    "    concat_df = concat_df.sample(frac=1).reset_index(drop=True)\n",
    "    in_x_train = series_to_tensor(concat_df['image'])\n",
    "    out_x_train = series_to_tensor(concat_df['imagePair'])\n",
    "    return [in_x_train, out_x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f2999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[trad_ae_x_in,  trad_ae_x_out]= prepare_train_traditional_autoencoder_data(train_df)\n",
    "\n",
    "[cross_same_class_ae_x_in,  cross_same_class_ae_x_out]= prepare_train_cross_same_class_autoencoder_data(train_df, same_class_cross_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653ed98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c3ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 8)           0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 8)           0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 8, 8, 8)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 16, 16, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSamplin  (None, 28, 28, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 1)         145       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4385 (17.13 KB)\n",
      "Trainable params: 4385 (17.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd7b7e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "235/235 [==============================] - 15s 58ms/step - loss: 0.2864 - val_loss: 0.1733\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.1551 - val_loss: 0.1423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f0a28c45690>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(trad_ae_x_in, trad_ae_x_in,\n",
    "                epochs=2,#100\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fce0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "class Autoencoder(keras.Model):\n",
    "    def __init__(self, latent_dim, input_shape ):\n",
    "        super(Autoencoder, self).__init__(input_shape,input_shape)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.shape = input_shape\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            input_shape,\n",
    "            layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "        ])\n",
    "        encoder_output_shape = self.encoder.layers[-1].output_shape\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same', input_shape=encoder_output_shape[1:]),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs,training = False):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "input_shape = keras.Input(shape=(28, 28, 1))\n",
    "latent_dim = 2\n",
    "ae = Autoencoder(latent_dim, input_shape)\n",
    "ae.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0aee4ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 4, 4, 8)           1904      \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 28, 28, 1)         2481      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4385 (17.13 KB)\n",
      "Trainable params: 4385 (17.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7db29194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "235/235 [==============================] - 13s 54ms/step - loss: 0.1297 - val_loss: 0.1255\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 13s 55ms/step - loss: 0.1240 - val_loss: 0.1214\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 13s 55ms/step - loss: 0.1202 - val_loss: 0.1175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f0a1948e860>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ae.fit(trad_ae_x_in, trad_ae_x_in,\n",
    "                epochs=3,#100\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                workers=6,\n",
    "                use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19b05111-3762-494b-8629-6217d32f71cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train autoencoder\n",
    "# plot loss ae\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "62ae07bc-3346-4852-9eaf-923a077549f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare data aumentated for same class match\n",
    "# train VAE \n",
    "# plot loss vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c353b218-6261-46ec-84ca-beb69852f5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate encoded_vector_ae using autoencoder\n",
    "# calculate encoded_vector_vae using Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aea79c74-becf-4c31-bc64-02559ca94498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create function to calculate metric topK class metric\n",
    "# calculateMetric(encoded_vector_ae)\n",
    "# calculateMetric(encoded_vector_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24676f1e-eae5-4ac4-928e-2527739e3233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data visualisation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b28ecc1-7480-4b90-b15c-703302195d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# discuss results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a3847-9a99-4b6e-9939-8ee23bd781cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is time, apply in another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405144b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
