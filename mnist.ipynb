{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd44d7a3-349b-4793-b42a-ae3d0b32e50c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 21:27:06.035748: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-05 21:27:06.924318: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-05 21:27:06.924365: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-05 21:27:06.930320: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-05 21:27:07.463782: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-05 21:27:07.467153: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-05 21:27:09.918426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a5e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from pyspark.sql.types import StructType,StructField, StringType, FloatType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9bea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3df554-27da-41e1-9756-0cedc4998fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train, test load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize values to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c42cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PY SPARK VERSION OF THE DATAFRAME\n",
    "# def get_ps_dataFrame(x_data,y_data):\n",
    "#     data_unified = [( x_data[i].tolist(), str(y_data[i])) for i in range(len(x_data))]\n",
    "#     schema = StructType([ \n",
    "#         StructField(\"image\",ArrayType(ArrayType(FloatType())),False), \n",
    "#         StructField(\"class\", StringType(), False) \n",
    "#       ])\n",
    "#     df = spark.createDataFrame(data=data_unified,schema=schema)\n",
    "#     return df\n",
    "# train_df = get_ps_dataFrame(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc0ede4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa5888ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_dataFrame(x_data,y_data):\n",
    "    return pd.DataFrame(data={'image':x_data.tolist(), 'class':y_data.tolist()})\n",
    "train_df = get_pd_dataFrame(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38eeb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_cross_same_class_pair(df:pd.DataFrame):\n",
    "    sorted_df = df.sort_values(\"class\").reset_index(drop=True)\n",
    "    shuffled_sorted_df = sorted_df.sample(frac=1).reset_index(drop=True).sort_values(\"class\").reset_index(drop=True)\n",
    "    shuffled_sorted_df.rename(columns={'image':'imagePair',\"class\": \"classPair\"}, inplace=True)\n",
    "    result = pd.concat([sorted_df, shuffled_sorted_df], axis=1)\n",
    "    return result[['image','imagePair', 'class']].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "same_class_cross_df = augment_data_cross_same_class_pair(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1875063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def series_to_tensor(series):\n",
    "    tensor_list = series.apply(lambda x: tf.constant(x))\n",
    "    return tf.stack(tensor_list)\n",
    "    \n",
    "def prepare_train_traditional_autoencoder_data(train_df):\n",
    "    image_tensor = series_to_tensor(train_df['image'])\n",
    "    in_x_train = image_tensor\n",
    "    out_x_train = image_tensor\n",
    "    return [in_x_train, out_x_train]\n",
    "\n",
    "def prepare_train_cross_same_class_autoencoder_data(train_df, additional_same_class_df):\n",
    "    original_df =  train_df.copy()\n",
    "    original_df[\"imagePair\"] = original_df[\"image\"]\n",
    "    concat_df = pd.concat([original_df, additional_same_class_df])\n",
    "    concat_df = concat_df.sample(frac=1).reset_index(drop=True)\n",
    "    in_x_train = series_to_tensor(concat_df['image'])\n",
    "    out_x_train = series_to_tensor(concat_df['imagePair'])\n",
    "    return [in_x_train, out_x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f2999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[trad_ae_x_in,  trad_ae_x_out]= prepare_train_traditional_autoencoder_data(train_df)\n",
    "\n",
    "[cross_same_class_ae_x_in,  cross_same_class_ae_x_out]= prepare_train_cross_same_class_autoencoder_data(train_df, same_class_cross_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9fce0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "class Autoencoder(keras.Model):\n",
    "    def __init__(self, latent_dim, input_shape ):\n",
    "        super(Autoencoder, self).__init__(input_shape,input_shape)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.shape = input_shape\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            input_shape,\n",
    "            layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2,2), padding='same'),\n",
    "        ])\n",
    "        encoder_output_shape = self.encoder.layers[-1].output_shape\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same', input_shape=encoder_output_shape[1:]),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs,training = False):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "input_shape = keras.Input(shape=(28, 28, 1))\n",
    "latent_dim = 2\n",
    "ae = Autoencoder(latent_dim, input_shape)\n",
    "ae.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0aee4ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_10 (Sequential)  (None, 4, 4, 8)           1904      \n",
      "                                                                 \n",
      " sequential_11 (Sequential)  (None, 28, 28, 1)         2481      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4385 (17.13 KB)\n",
      "Trainable params: 4385 (17.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7db29194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60/60 [==============================] - 14s 219ms/step - loss: 0.1354 - val_loss: 0.1140\n",
      "Epoch 2/3\n",
      "60/60 [==============================] - 13s 211ms/step - loss: 0.1120 - val_loss: 0.1140\n",
      "Epoch 3/3\n",
      "60/60 [==============================] - 13s 216ms/step - loss: 0.1120 - val_loss: 0.1140\n"
     ]
    }
   ],
   "source": [
    "# train autoencoder\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# specify the path where you want to save your models\n",
    "checkpoint_file_path =  './checkpoints/ae'\n",
    "\n",
    "# create a model checkpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_file_path, \n",
    "    monitor='val_loss',\n",
    "    verbose=0, \n",
    "    save_weights_only=True, \n",
    "    save_best_only=False,\n",
    "    mode='min', \n",
    "    save_freq=\"epoch\")\n",
    "\n",
    "history = ae.fit(trad_ae_x_in, trad_ae_x_in,\n",
    "                epochs=3,#100\n",
    "                batch_size=1000,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[checkpoint] ,\n",
    "                workers=8,\n",
    "                use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "648d7676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fd14417fe20>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ae.load_weights(checkpoint_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b35aa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.predict of <keras.src.engine.sequential.Sequential object at 0x7fd166917730>>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19b05111-3762-494b-8629-6217d32f71cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4557/2782030354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# plot loss ae\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62ae07bc-3346-4852-9eaf-923a077549f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare data aumentated for same class match\n",
    "# train VAE \n",
    "# plot loss vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c353b218-6261-46ec-84ca-beb69852f5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate encoded_vector_ae using autoencoder\n",
    "# calculate encoded_vector_vae using Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aea79c74-becf-4c31-bc64-02559ca94498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create function to calculate metric topK class metric\n",
    "# calculateMetric(encoded_vector_ae)\n",
    "# calculateMetric(encoded_vector_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24676f1e-eae5-4ac4-928e-2527739e3233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data visualisation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b28ecc1-7480-4b90-b15c-703302195d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# discuss results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a3847-9a99-4b6e-9939-8ee23bd781cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is time, apply in another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405144b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
